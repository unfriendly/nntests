{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Prepare 'System' if Conditions not met\n",
    "!pip install --upgrade pip\n",
    "!pip install tensorflow matplot numpy pandas sklearn keras seaborn requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Created By Unfriendly \n",
    "#(A simple Jupyter Notebook in Binder for Crypto price prediction)\n",
    "\n",
    "historical_start = \"6yr,0mon,0day,0hr,0min,0sec\"\n",
    "# How long to historically look back at data\n",
    "\n",
    "predict_into = \"0yr,0mon,10day,0hr,0min,0sec\" \n",
    "# How far to try and predict into the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "for dirname, _, filenames in os.walk('/unfriendly/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data timestamps\n",
    "import time\n",
    "import datetime\n",
    "one_yr = 31536000000\n",
    "one_mon = one_yr/12\n",
    "one_day = one_yr/365\n",
    "one_hr = one_day/24\n",
    "one_min = one_hr/60\n",
    "one_sec = one_min/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare how far to look back in the past in UNIX time-format\n",
    "history_split = historical_start.replace('yr', '')\n",
    "history_res = history_split.replace('mon', '')\n",
    "history_split = history_res.replace('day', '')\n",
    "history_res = history_split.replace('hr', '')\n",
    "history_split = history_res.replace('min', '')\n",
    "history_res = history_split.replace('sec', '')\n",
    "history_split = history_res.split(\",\")\n",
    "print(history_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare how far to predict into the future in UNIX time-format\n",
    "predict_split = predict_into.replace('yr', '')\n",
    "predict_res = predict_split.replace('mon', '')\n",
    "predict_split = predict_res.replace('day', '')\n",
    "predict_res = predict_split.replace('hr', '')\n",
    "predict_split = predict_res.replace('min', '')\n",
    "predict_res = predict_split.replace('sec', '')\n",
    "predict_split = predict_res.split(\",\")\n",
    "print(predict_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_array_yr = int(history_split[0])\n",
    "unix_hist_yr = one_yr*history_array_yr\n",
    "\n",
    "history_array_mon = int(history_split[1])\n",
    "unix_hist_mon = one_mon*history_array_mon\n",
    "\n",
    "history_array_day = int(history_split[2])\n",
    "unix_hist_day = one_day*history_array_day\n",
    "\n",
    "history_array_hr = int(history_split[3])\n",
    "unix_hist_hr = one_hr*history_array_hr\n",
    "\n",
    "history_array_min = int(history_split[4])\n",
    "unix_hist_min = one_min*history_array_min\n",
    "\n",
    "history_array_sec = int(history_split[5])\n",
    "unix_hist_sec = one_sec*history_array_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_array_yr = int(predict_split[0])\n",
    "unix_pred_yr = one_yr*predict_array_yr\n",
    "\n",
    "predict_array_mon = int(predict_split[1])\n",
    "unix_pred_mon = one_mon*predict_array_mon\n",
    "\n",
    "predict_array_day = int(predict_split[2])\n",
    "unix_pred_day = one_day*predict_array_day\n",
    "\n",
    "predict_array_hr = int(predict_split[3])\n",
    "unix_pred_hr = one_hr*predict_array_hr\n",
    "\n",
    "predict_array_min = int(predict_split[4])\n",
    "unix_pred_min = one_min*predict_array_min\n",
    "\n",
    "predict_array_sec = int(predict_split[5])\n",
    "unix_pred_sec = one_sec*predict_array_sec\n",
    "\n",
    "unix_prediction = unix_pred_yr+unix_pred_mon+unix_pred_day+unix_pred_hr+unix_pred_min+unix_pred_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_time = time.time()\n",
    "int_time = int(raw_time)\n",
    "current_time = str(int_time)\n",
    "\n",
    "unix_start = unix_hist_yr+unix_hist_mon+unix_hist_day+unix_hist_hr+unix_hist_min+unix_hist_sec\n",
    "raw_start = raw_time - unix_start\n",
    "\n",
    "int_start = int(raw_start)\n",
    "start = str(int_start)\n",
    "\n",
    "#print(unix_hist_yr+history_array_mon+history_array_day+history_array_hr+history_array_min+history_array_sec)\n",
    "print(start + ' - start')\n",
    "\n",
    "gather_count = int_start/(7*one_day)\n",
    "gather_int = int(gather_count)\n",
    "gather_str = str(gather_int)\n",
    "pos_gather_count = abs(int(gather_count))\n",
    "pos_gather_str = str(pos_gather_count)\n",
    "\n",
    "print(gather_str + ' - gather')\n",
    "print(pos_gather_str + ' - positive gather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_dt = datetime.datetime.now()\n",
    "\n",
    "print(int(c_dt.strftime(\"%s\")))\n",
    "\n",
    "c_dt_array_year = history_array_yr*365\n",
    "\n",
    "history_array_comb = history_array_day + c_dt_array_year\n",
    "\n",
    "#c_dt_start = int_time\n",
    "\n",
    "c_dt_start = datetime.datetime.now() - datetime.timedelta(days=history_array_comb,hours=history_array_hr,minutes=history_array_min,seconds=history_array_sec)\n",
    "\n",
    "#c_dt_str = str(c_dt_start)\n",
    "\n",
    "#print(c_dt_str)\n",
    "\n",
    "data_count = 0\n",
    "\n",
    "c_dt_end = c_dt_start + datetime.timedelta(days=7) \n",
    "c_dt_raw_end = c_dt_end.strftime(\"%s\")\n",
    "c_dt_raw = c_dt_start.strftime(\"%s\")\n",
    "c_dt_int = int(c_dt_raw)\n",
    "c_dt_end_int = int(c_dt_raw_end)\n",
    "c_dt_end_str = str(c_dt_raw_end)\n",
    "c_dt_str = str(c_dt_raw)\n",
    "print(c_dt_int)\n",
    "print(c_dt_end_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "#while count < pos_gather_count:\n",
    "while data_count < 1:\n",
    "    \n",
    "    d_u=\"https://query1.finance.yahoo.com/v7/finance/download/BTC-USD?period1=1411862400&period2=\" + current_time + \"&interval=1d&events=history&includeAdjustedClose=true\"\n",
    "    \n",
    "    #d_u=\"https://query1.finance.yahoo.com/v7/finance/download/BTC-USD?period1=1411862400&period2=1612158064&interval=1d&events=history&includeAdjustedClose=true\"\n",
    "    \n",
    "    #d_u=\"https://query1.finance.yahoo.com/v7/finance/download/BTC-USD?period1=\"+dt_str+\"&period2=\"+dt_end_str+\"&interval=1d&events=history&includeAdjustedClose=true\"\n",
    "    #d_u=\"https://query1.finance.yahoo.com/v7/finance/download/BTC-USD?period1=\"+gather_str+\"&period2=\"+current_time+\"&interval=1m&events=history&includeAdjustedClose=true\"\n",
    "    \n",
    "    print(d_u)\n",
    "    \n",
    "    with urllib.request.urlopen(d_u) as testfile, open('dataset.csv', 'w') as f:\n",
    "        f.write(testfile.read().decode())\n",
    "\n",
    "    data_count += 1  # This is the same as count = count + 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(start + ' - start')\n",
    "print(current_time + ' - current time')\n",
    "print(d_u + ' - url')\n",
    "    \n",
    "print(gather_count)\n",
    "#print(data_count)\n",
    "\n",
    "# List all CSV files in the working dir\n",
    "extension = \"csv\"\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "print(all_filenames)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import urllib.request\n",
    "d_u=\"https://query1.finance.yahoo.com/v7/finance/download/BTC-USD?period1=1411862400&period2=1612158064&interval=1d&events=history&includeAdjustedClose=true\"\n",
    "\n",
    "\n",
    "with urllib.request.urlopen(d_u) as testfile, open('dataset.csv', 'w') as f:\n",
    "    f.write(testfile.read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('dataset.csv')\n",
    "\n",
    "data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "#data=data.dropna()\n",
    "#data=data.dropna(inplace=True)\n",
    "#data=data.dropna(subset=['Close'])\n",
    "#data=data.dropna(how='any',axis=1)\n",
    "\n",
    "data.dropna(subset=['Close'], inplace=True)\n",
    "data.reset_index(drop=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=data['Close']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size=int(len(df1)*0.65)\n",
    "test_size=len(df1)-training_size\n",
    "train_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size,test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-time_step-1):\n",
    "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + time_step, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t,t+1,t+2,t+3 and Y=t+4\n",
    "time_step = 100\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, ytest = create_dataset(test_data, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape), print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape), print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the Stacked LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = Adam(lr=0.0001)\n",
    "\n",
    "opt = Adam(lr=0.0025)\n",
    "\n",
    "model=Sequential()\n",
    "model.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\n",
    "model.add(LSTM(50,return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "#model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "model.compile(optimizer=opt, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,ytest),epochs=100,batch_size=128,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "### Do the prediction and check performance metrics\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)\n",
    "##Transformback to original form\n",
    "train_predict=scaler.inverse_transform(train_predict)\n",
    "test_predict=scaler.inverse_transform(test_predict)\n",
    "### Calculate RMSE performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "math.sqrt(mean_squared_error(y_train,train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test Data RMSE\n",
    "math.sqrt(mean_squared_error(ytest,test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "look_back=100\n",
    "trainPredictPlot = numpy.empty_like(df1)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(df1)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(df1))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input=test_data[707:].reshape(1,-1)\n",
    "x_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input=list(x_input)\n",
    "temp_input=temp_input[0].tolist()\n",
    "\n",
    "temp_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate prediction for next 10 days\n",
    "from numpy import array\n",
    "\n",
    "lst_output=[]\n",
    "n_steps=103\n",
    "i=0\n",
    "while(i<30):\n",
    "    \n",
    "    if(len(temp_input)>100):\n",
    "        #print(temp_input)\n",
    "        x_input=np.array(temp_input[1:])\n",
    "        print(\"{} day input {}\".format(i,x_input))\n",
    "        x_input=x_input.reshape(1,-1)\n",
    "        x_input = x_input.reshape((1, n_steps, 1))\n",
    "        #print(x_input)\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        print(\"{} day output {}\".format(i,yhat))\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        temp_input=temp_input[1:]\n",
    "        #print(temp_input)\n",
    "        lst_output.extend(yhat.tolist())\n",
    "        i=i+1\n",
    "    else:\n",
    "        x_input = x_input.reshape((1, n_steps,1))\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        print(yhat[0])\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        print(len(temp_input))\n",
    "        lst_output.extend(yhat.tolist())\n",
    "        i=i+1\n",
    "    \n",
    "\n",
    "print(lst_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_new=np.arange(1,101)\n",
    "day_pred=np.arange(101,131)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(day_new,scaler.inverse_transform(df1[2205:]))\n",
    "plt.plot(day_pred,scaler.inverse_transform(lst_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df1.tolist()\n",
    "df3.extend(lst_output)\n",
    "plt.plot(df3[2206:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=scaler.inverse_transform(df3).tolist()\n",
    "plt.plot(df3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
